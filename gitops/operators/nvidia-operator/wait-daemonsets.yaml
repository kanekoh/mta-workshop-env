apiVersion: batch/v1
kind: Job
metadata:
  name: wait-nvidia-daemonsets
  namespace: nvidia-gpu-operator
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
    argocd.argoproj.io/sync-wave: "4"
spec:
  template:
    metadata:
      name: wait-nvidia-daemonsets
    spec:
      serviceAccountName: nvidia-daemonset-waiter
      restartPolicy: OnFailure
      containers:
      - name: wait-daemonsets
        image: registry.redhat.io/openshift4/ose-cli:latest
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          echo "Waiting for NVIDIA DaemonSets to be ready on GPU nodes..."
          
          # GPU Nodeのラベルを確認（NFDが設定したラベルを使用）
          GPU_NODE_LABEL="feature.node.kubernetes.io/pci-10de.present=true"
          
          # GPU Nodeを取得
          GPU_NODES=$(oc get nodes -l "${GPU_NODE_LABEL}" -o jsonpath='{.items[*].metadata.name}' || echo "")
          
          if [ -z "$GPU_NODES" ]; then
            echo "Warning: No GPU nodes found with label ${GPU_NODE_LABEL}"
            echo "Checking for nodes with nvidia.com/gpu.present label..."
            GPU_NODES=$(oc get nodes -l "nvidia.com/gpu.present=true" -o jsonpath='{.items[*].metadata.name}' || echo "")
          fi
          
          if [ -z "$GPU_NODES" ]; then
            echo "Error: No GPU nodes found. Please ensure NFD Operator has labeled GPU nodes."
            exit 1
          fi
          
          echo "Found GPU nodes: ${GPU_NODES}"

          # ラベル app.kubernetes.io/component=nvidia-driver を持つDSを探す
          DRIVER_DS_NAME=$(oc get daemonset -n nvidia-gpu-operator -l app.kubernetes.io/component=nvidia-driver -o jsonpath='{.items[0].metadata.name}' || echo "nvidia-driver-daemonset")
          
          # 待機するDaemonSetのリスト
          DAEMONSETS=(
            "${DRIVER_DS_NAME}"
            "${CONTAINER_TOOLKIT_DS_NAME}"
            "nvidia-device-plugin-daemonset"
            "nvidia-dcgm-exporter"
            "nvidia-node-status-exporter"
            "nvidia-operator-validator"
          )
          
          MAX_WAIT=1800  # 30分
          ELAPSED=0
          INTERVAL=10
          
          while [ $ELAPSED -lt $MAX_WAIT ]; do
            ALL_READY=true
            
            for DS in "${DAEMONSETS[@]}"; do
              # DaemonSetが存在するか確認
              if ! oc get daemonset "${DS}" -n nvidia-gpu-operator &>/dev/null; then
                echo "DaemonSet ${DS} not found yet, waiting..."
                ALL_READY=false
                continue
              fi
              
              # DaemonSetの状態を確認
              DESIRED=$(oc get daemonset "${DS}" -n nvidia-gpu-operator -o jsonpath='{.status.desiredNumberScheduled}' || echo "0")
              READY=$(oc get daemonset "${DS}" -n nvidia-gpu-operator -o jsonpath='{.status.numberReady}' || echo "0")
              
              if [ "$DESIRED" = "0" ] || [ "$READY" != "$DESIRED" ]; then
                echo "DaemonSet ${DS}: Ready ${READY}/${DESIRED}"
                ALL_READY=false
              else
                echo "DaemonSet ${DS}: Ready ${READY}/${DESIRED} ✓"
              fi
            done
            
            if [ "$ALL_READY" = "true" ]; then
              echo "All NVIDIA DaemonSets are ready!"
              
              # GPU Node上で実際にPodが実行されているか確認
              for NODE in $GPU_NODES; do
                echo "Checking pods on node ${NODE}..."
                PODS_ON_NODE=$(oc get pods -n nvidia-gpu-operator --field-selector spec.nodeName="${NODE}" -o jsonpath='{.items[*].metadata.name}' || echo "")
                if [ -z "$PODS_ON_NODE" ]; then
                  echo "Warning: No NVIDIA pods found on node ${NODE}"
                else
                  echo "Found pods on ${NODE}: ${PODS_ON_NODE}"
                  for POD in $PODS_ON_NODE; do
                    POD_STATUS=$(oc get pod "${POD}" -n nvidia-gpu-operator -o jsonpath='{.status.phase}' || echo "Unknown")
                    if [ "$POD_STATUS" != "Running" ]; then
                      echo "Pod ${POD} is not Running (status: ${POD_STATUS})"
                      ALL_READY=false
                    fi
                  done
                fi
              done
              
              if [ "$ALL_READY" = "true" ]; then
                echo "All NVIDIA DaemonSets are ready and pods are running on GPU nodes!"
                exit 0
              fi
            fi
            
            echo "Waiting ${INTERVAL} seconds... (${ELAPSED}/${MAX_WAIT}s elapsed)"
            sleep $INTERVAL
            ELAPSED=$((ELAPSED + INTERVAL))
          done
          
          echo "Timeout: Not all NVIDIA DaemonSets became ready within ${MAX_WAIT} seconds"
          echo "Current status:"
          for DS in "${DAEMONSETS[@]}"; do
            if oc get daemonset "${DS}" -n nvidia-gpu-operator &>/dev/null; then
              DESIRED=$(oc get daemonset "${DS}" -n nvidia-gpu-operator -o jsonpath='{.status.desiredNumberScheduled}' || echo "0")
              READY=$(oc get daemonset "${DS}" -n nvidia-gpu-operator -o jsonpath='{.status.numberReady}' || echo "0")
              echo "  ${DS}: ${READY}/${DESIRED}"
            else
              echo "  ${DS}: not found"
            fi
          done
          exit 1
        env:
        - name: KUBECONFIG
          value: /var/run/secrets/kubernetes.io/serviceaccount
